{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kev-in-xu/Phylo-Exceptions/blob/main/Organisms_lacking_Dmc1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOCKuzdIH-bR",
        "outputId": "822f8b81-f681-4651-cb40-e0acf526c7b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.81-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.23.5)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.81\n",
            "env: STORAGE_FILE_PATH=/content/drive/MyDrive/Greene-Lab/lacking_organisms/nov_data/\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "!pip install biopython\n",
        "from Bio.Blast import NCBIWWW, NCBIXML\n",
        "from Bio import SeqIO\n",
        "from Bio import Entrez\n",
        "\n",
        "import requests\n",
        "\n",
        "#%env STORAGE_FILE_PATH=/content/drive/MyDrive/Greene_lab/\n",
        "%env STORAGE_FILE_PATH=/content/drive/MyDrive/Greene-Lab/lacking_organisms/nov_data/\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# ! ls $STORAGE_FILE_PATH\n",
        "\n",
        "\n",
        "Entrez.api_key = \"a5d84a29ce91f0aa01001ad64a26fc145208\"\n",
        "Entrez.email = \"kkx2102@columbia.edu\"\n",
        "path = %env STORAGE_FILE_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmQq9L5TIz02"
      },
      "source": [
        "### Workbook upload / parsing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "8j0V2FZtJC9Q",
        "outputId": "cc71df99-9d0e-4d9c-cf16-d3b806b15d00"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-137-2979efe614b8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'env'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'STORAGE_FILE_PATH'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrad51\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Rad51_Workbook.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdmc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Dmc1_Workbook.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1650\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1653\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1526\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Greene_lab/Rad51_Workbook.xlsx'"
          ]
        }
      ],
      "source": [
        "path = %env STORAGE_FILE_PATH\n",
        "rad51 = pd.read_excel(path + \"Rad51_Workbook.xlsx\")\n",
        "dmc1 = pd.read_excel(path + \"Dmc1_Workbook.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GbajaenLa8G"
      },
      "outputs": [],
      "source": [
        "f = open(path + \"Dmc1_seqdump.txt\", \"r\")\n",
        "sequences = []\n",
        "current_sequence = {\"header\": \"\", \"sequence\": \"\"}\n",
        "\n",
        "# Open and read the FASTA file\n",
        "with open(path + \"Dmc1_seqdump.txt\", \"r\") as fasta_file:\n",
        "    for line in fasta_file:\n",
        "        line = line.strip()\n",
        "        if line.startswith(\">\"):  # Header line\n",
        "            if current_sequence[\"header\"]:\n",
        "                sequences.append(current_sequence.copy())\n",
        "            current_sequence[\"header\"] = line[1:]  # Remove '>' from header\n",
        "            current_sequence[\"sequence\"] = \"\"\n",
        "        else:  # Sequence line\n",
        "            current_sequence[\"sequence\"] += line\n",
        "\n",
        "# Don't forget to add the last sequence after the loop\n",
        "if current_sequence[\"header\"]:\n",
        "    sequences.append(current_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M080s00KMAhU"
      },
      "outputs": [],
      "source": [
        "Dmc1_orgs = []\n",
        "\n",
        "for seq in sequences:\n",
        "  for a in seq[\"header\"].split():\n",
        "    if a.startswith(\"[\"):\n",
        "      Dmc1_orgs.append(a[1:])\n",
        "\n",
        "dmc1_genus = list(set([org for org in Dmc1_orgs]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTPuOZn5Q7kw"
      },
      "source": [
        "### pBLAST Automation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "2tBnmOY9Q6e6",
        "outputId": "93f34da0-c565-4a6c-dabd-aa3e9c6694c4"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-5fa185ef6227>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Perform pBLAST search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mresult_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNCBIWWW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqblast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"blastp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"refseq_protein\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhitlist_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Parse the BLAST results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/Bio/Blast/NCBIWWW.py\u001b[0m in \u001b[0;36mqblast\u001b[0;34m(program, database, sequence, url_base, auto_format, composition_based_statistics, db_genetic_code, endpoints, entrez_query, expect, filter, gapcosts, genetic_code, hitlist_size, i_thresh, layout, lcase_mask, matrix_name, nucl_penalty, nucl_reward, other_advanced, perc_ident, phi_pattern, query_file, query_believe_defline, query_from, query_to, searchsp_eff, service, threshold, ungapped_alignment, word_size, short_query, alignments, alignment_view, descriptions, entrez_links_new_window, expect_low, expect_high, format_entrez_query, format_object, format_type, ncbi_gi, results_file, show_overview, megablast, template_type, template_length, username, password)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mwait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqblast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_previous\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdelay\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcurrent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m             \u001b[0mqblast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_previous\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "### edited from ChatGPT\n",
        "\n",
        "yeast_seq = \"MSVTGTEIDSDTAKNILSVDELQNYGINASDLQKLKSGGIYTVNTVLSTTRRHLCKIKGLSEVKVEKIKEAAGKIIQVGFIPATVQLDIRQRVYSLSTGSKQLDSILGGGIMTMSITEVFGEFRCGKTQMSHTLCVTTQLPREMGGGEGKVAYIDTEGTFRPERIKQIAEGYELDPESCLANVSYARALNSEHQMELVEQLGEELSSGDYRLIVVDSIMANFRVDYCGRGELSERQQKLNQHLFKLNRLAEEFNVAVFLTNQVQSDPGASALFASADGRKPIGGHVLAHASATRILLRKGRGDERVAKLQDSPDMPEKECVYVIGEKGITDSSD\"\n",
        "\n",
        "human_seq = \"MKEDQVVAEEPGFQDEEESLFQDIDLLQKHGINVADIKKLKSVGICTIKGIQMTTRRALCNVKGLSEAKVDKIKEAANKLIEPGFLTAFEYSEKRKMVFHITTGSQEFDKLLGGGIESMAITEAFGEFRTGKTQLSHTLCVTAQLPGAGGYPGGKIIFIDTENTFRPDRLRDIADRFNVDHDAVLDNVLYARAYTSEHQMELLDYVAAKFHEEAGIFKLLIIDSIMALFRVDFSGRGELAERQQKLAQMLSRLQKISEEYNVAVFVTNQMTADPGATMTFQADPKKPIGGHILAHASTTRISLRKGRGELRIAKIYDSPEMPENEATFAITAGGIGDAKE\"\n",
        "\n",
        "# Replace this with your actual query sequence in FASTA format\n",
        "# query_seq = \">Query\\n\" + yeast_seq\n",
        "query_seq = \">Query\\n\" + human_seq\n",
        "\n",
        "# Perform pBLAST search\n",
        "result_handle = NCBIWWW.qblast(\"blastp\", \"refseq_protein\", query_seq, hitlist_size=500)\n",
        "\n",
        "# Parse the BLAST results\n",
        "blast_records = NCBIXML.parse(result_handle)\n",
        "\n",
        "# List to store organisms without DMC1 or HSLIM15 entry\n",
        "organisms_without_entry = []\n",
        "organisms = []\n",
        "\n",
        "# Iterate through BLAST records\n",
        "for record in blast_records:\n",
        "    for alignment in record.alignments:\n",
        "        organisms.append(alignment.title.split(\"[\")[1].split(\"]\")[0])\n",
        "\n",
        "#alignment_title = alignment.title\n",
        "# Check if alignment title contains DMC1 or HSLIM15\n",
        "#if \"DMC1\" not in alignment_title.upper() and \"HSLIM15\" not in alignment_title.upper():\n",
        " #   organism = alignment_title.split(\"[\")[1].split(\"]\")[0]\n",
        "  #  organisms_without_entry.append(organism)\n",
        "\n",
        "\n",
        "# Print organisms without DMC1/HSLIM15 entry\n",
        "print(\"Organisms without DMC1 or HSLIM15 entry:\")\n",
        "for organism in organisms_without_entry:\n",
        "    print(organism)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJFXPYpzrIkE",
        "outputId": "4cef73c2-6157-40ba-f40c-b088a8aa613a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(record.alignments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXw-1oniq0l2",
        "outputId": "1469d128-c4ca-4230-8cdb-079abdf6987b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6.27023e-124"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "alignment.hsps[0].expect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryXPc0hlaORw"
      },
      "outputs": [],
      "source": [
        "organisms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slgJTtpeKDPG"
      },
      "source": [
        "### BLASTing exceptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pUbZRmqKK8r"
      },
      "outputs": [],
      "source": [
        "#path = %env STORAGE_FILE_PATH\n",
        "# opens excel files\n",
        "#rad51 = pd.read_excel(path + \"Rad51_Workbook.xlsx\")\n",
        "# opens files\n",
        "#f = open(path + \"Dmc1_seqdump.txt\", \"r\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rXrnpsCKYxx"
      },
      "outputs": [],
      "source": [
        "path = %env STORAGE_FILE_PATH\n",
        "Dmc1branch = open(path + \"Dmc1branch_240-520_85.fa.clstr\", \"r\")\n",
        "\n",
        "pblastSeqs = []\n",
        "current_sequence = {\"header\": \"\",\"accession no.\": \"\",\n",
        "                    \"organism\": \"\", \"sequence\": \"\", \"length\": \"\"}\n",
        "\n",
        "# Open and read the pBLAST FASTA file\n",
        "with open(path + \"Rad51_1e-25_7693.fasta\", \"r\") as pblastResult:\n",
        "    for line in pblastResult:\n",
        "        line = line.strip()\n",
        "        if line.startswith(\">\"):  # Header line\n",
        "            if current_sequence[\"header\"]:\n",
        "              current_sequence[\"length\"] = len(current_sequence[\"sequence\"])\n",
        "              pblastSeqs.append(current_sequence.copy())\n",
        "            current_sequence[\"header\"] = line[1:]  # Remove '>' from header\n",
        "            current_sequence[\"sequence\"] = \"\"\n",
        "            current_sequence[\"organism\"] = line[line.find(\"[\")+1:line.rfind(\"]\")]\n",
        "            current_sequence[\"accession no.\"] = line[1:line.find(\" \")]\n",
        "        else:  # Sequence line\n",
        "            current_sequence[\"sequence\"] += line\n",
        "\n",
        "# Don't forget to add the last sequence after the loop\n",
        "if current_sequence[\"header\"]:\n",
        "    pblastSeqs.append(current_sequence)\n",
        "\n",
        "master = pd.DataFrame.from_dict(pblastSeqs)\n",
        "\n",
        "\n",
        "###DMC1###\n",
        "Dmc1Clusters = []\n",
        "current_cluster = {\"accession no.\": \"\", \"protein\": \"\"}\n",
        "\n",
        "# Open and read the Dmc1 FASTA file\n",
        "with open(path + \"Dmc1branch_240-520_85.fa.clstr\", \"r\") as Dmc1File:\n",
        "    for line in Dmc1File:\n",
        "        line = line.strip()\n",
        "        if not line.startswith(\">\"):  # non-cluster line\n",
        "            current_cluster[\"accession no.\"] = line[line.find(\">\")+1:line.find(\".\")]\n",
        "            current_cluster[\"protein\"] = \"Dmc1\"\n",
        "            Dmc1Clusters.append(current_cluster.copy())\n",
        "Dmc1 = pd.DataFrame.from_dict(Dmc1Clusters)\n",
        "\n",
        "\n",
        "###RAD51###\n",
        "Rad51Clusters = []\n",
        "current_cluster = {\"accession no.\": \"\", \"protein\": \"\"}\n",
        "\n",
        "# Open and read the Dmc1 FASTA file\n",
        "with open(path + \"Rad51branch_240-520_85.fa.clstr\", \"r\") as Rad51File:\n",
        "    for line in Rad51File:\n",
        "        line = line.strip()\n",
        "        if not line.startswith(\">\"):  # non-cluster line\n",
        "            current_cluster[\"accession no.\"] = line[line.find(\">\")+1:line.find(\".\")]\n",
        "            current_cluster[\"protein\"] = \"Rad51\"\n",
        "            Rad51Clusters.append(current_cluster.copy())\n",
        "Rad51 = pd.DataFrame.from_dict(Rad51Clusters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKHNVCQOZirU"
      },
      "outputs": [],
      "source": [
        "# Merges Columns to include protein data\n",
        "master=master.merge(Rad51, how=\"left\", left_on=\"accession no.\", right_on=\"accession no.\")\n",
        "master=master.merge(Dmc1, how=\"left\", left_on=\"accession no.\", right_on=\"accession no.\")\n",
        "\n",
        "def combine_columns(row):\n",
        "    return row[\"protein_x\"] if pd.isna(row[\"protein_y\"]) else row[\"protein_y\"]\n",
        "\n",
        "master['protein'] = master.apply(combine_columns, axis=1)\n",
        "master.drop(columns=[\"protein_x\",\"protein_y\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCuDjn5qeFbD"
      },
      "outputs": [],
      "source": [
        "Rad51_orgs = list(master[\"organism\"][master[\"protein\"] == \"Rad51\"])\n",
        "Dmc1_orgs = list(master[\"organism\"][master[\"protein\"] == \"Dmc1\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjJM91uQffEp"
      },
      "outputs": [],
      "source": [
        "Rad51_orgs = list(set([org.split(\" \")[0] for org in Rad51_orgs]))\n",
        "Dmc1_orgs = list(set([org.split(\" \")[0] for org in Dmc1_orgs]))\n",
        "\n",
        "Rad51_only = [org for org in Rad51_orgs if org not in Dmc1_orgs]\n",
        "Dmc1_only = [org for org in Dmc1_orgs if org not in Rad51_orgs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55BLuqMZjb1p"
      },
      "outputs": [],
      "source": [
        "Rad51_only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvUBf5xO2Ix4"
      },
      "source": [
        "#### Mike's Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06U_u182ZmVO"
      },
      "outputs": [],
      "source": [
        "###RAD51###\n",
        "Rad51Clusters = []\n",
        "current_cluster = {\"accession no.\": \"\", \"protein\": \"\"}\n",
        "\n",
        "# Open and read the Dmc1 FASTA file\n",
        "with open(path + \"Rad51branch_240-520_85.fa.clstr\", \"r\") as Rad51File:\n",
        "    for line in Rad51File:\n",
        "        line = line.strip()\n",
        "        if not line.startswith(\">\"):  # non-cluster line\n",
        "            current_cluster[\"accession no.\"] = line[line.find(\">\")+1:line.find(\".\")]\n",
        "            current_cluster[\"protein\"] = \"Rad51\"\n",
        "            Rad51Clusters.append(current_cluster.copy())\n",
        "Rad51 = pd.DataFrame.from_dict(Rad51Clusters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZChJ4kiPcnJH"
      },
      "source": [
        "### Just using NCBI Taxonomy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuAYyFlMZnpi"
      },
      "outputs": [],
      "source": [
        "### PARSING ALL PHYLOGENETIC ORDERS FROM GIVEN FILES ###\n",
        "path = %env STORAGE_FILE_PATH\n",
        "orders = []\n",
        "\n",
        "with open(path + \"Metazoa_orders.txt\", \"r\") as taxonomy:\n",
        "  for line in taxonomy:\n",
        "    line = line.strip()\n",
        "    if line.find(\"-\") != -1 and line.find(\"---\") == -1:\n",
        "      orders.append(line[line.find(\"-\")+1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fH7VMo35v9QV"
      },
      "outputs": [],
      "source": [
        "##### GETS TAXIDS FROM LIST OF TAXONOMY RANKS ######\n",
        "\n",
        "IDs = []\n",
        "ID = {\"organism\": \"\", \"txid\": \"\", \"count\": \"\"}\n",
        "\n",
        "# Iterates through organisms\n",
        "for organism_name in orders:\n",
        "  # Construct the URL for the NCBI Taxonomy API\n",
        "  base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
        "  search_url = base_url + \"esearch.fcgi?db=taxonomy&term=\" + organism_name\n",
        "\n",
        "  # Send a GET request to the API\n",
        "  response = requests.get(search_url)\n",
        "  data = response.text\n",
        "\n",
        "  # Extract the TaxID from the response\n",
        "  if data.find(\"<Id>\")!=-1:\n",
        "    taxid = data[data.find(\"<Id>\")+4:data.find(\"</Id>\")]\n",
        "    print(f\"TaxID for {organism_name}: {taxid}\")\n",
        "  else:\n",
        "    taxid = \"\"\n",
        "    #print(f\"TaxID not found for {organism_name}\")\n",
        "\n",
        "  ID[\"organism\"]=organism_name\n",
        "  ID[\"txid\"]=taxid + \"[ORGN]\"\n",
        "\n",
        "  # Construct the URL for the NCBI Taxonomy API\n",
        "  base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
        "  search_url = base_url + \"esearch.fcgi?db=taxonomy&term=\" + organism_name + \"[Organism]\"\n",
        "\n",
        "  # Send a GET request to the API\n",
        "  response = requests.get(search_url)\n",
        "  data = response.text\n",
        "\n",
        "  # Extract the TaxID from the response\n",
        "  if data.find(\"<Count>\")!=-1:\n",
        "    count = data[data.find(\"<Count>\")+7:data.find(\"</Count>\")]\n",
        "    print(f\"Count for {organism_name}: {count}\")\n",
        "  else:\n",
        "    count = 0\n",
        "    #print(f\"TaxID not found for {organism_name}\")\n",
        "\n",
        "  ID[\"count\"]=count\n",
        "  IDs.append(ID.copy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJ6EhhKcFLGS"
      },
      "outputs": [],
      "source": [
        "IDs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnc81vAMsPvN",
        "outputId": "d677c022-b54b-40b0-a367-9beaa48c3f92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TaxID for Haplosclerida: 6049\n"
          ]
        }
      ],
      "source": [
        "base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
        "search_url = base_url + \"esearch.fcgi?db=taxonomy&term=\" + organism_name\n",
        "\n",
        "# Send a GET request to the API\n",
        "response = requests.get(search_url)\n",
        "data = response.text\n",
        "\n",
        "# Extract the TaxID from the response\n",
        "if data.find(\"<Id>\")!=-1:\n",
        "  taxid = data[data.find(\"<Id>\")+4:data.find(\"</Id>\")]\n",
        "  print(f\"TaxID for {organism_name}: {taxid}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAtoeFSxdftB"
      },
      "outputs": [],
      "source": [
        "### Exports Taxids to csv ####\n",
        "import csv\n",
        "\n",
        "field_names = ['organism', 'txid', 'count']\n",
        "\n",
        "with open(path +'Names.csv', 'w') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames = field_names)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(IDs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K35d1dJ3HMkk"
      },
      "source": [
        "#### Read CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUSwGeoydLlm"
      },
      "outputs": [],
      "source": [
        "### Reads existing csv for dictionary ###\n",
        "\n",
        "path = %env STORAGE_FILE_PATH\n",
        "\n",
        "IDs = []\n",
        "with open(path +'Names.csv', 'r') as csvfile:\n",
        "  csv_reader = csv.DictReader(csvfile)\n",
        "  for row in csv_reader:\n",
        "    IDs.append(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stPW-YLwgB0F"
      },
      "outputs": [],
      "source": [
        "zeroes = []\n",
        "\n",
        "for org in IDs:\n",
        "  if int(org[\"count\"]) == 0 or org[\"txid\"] == \"[ORGN]\":\n",
        "    zeroes.append(org)\n",
        "\n",
        "\n",
        "zero_orgs = []\n",
        "\n",
        "for org in zeroes:\n",
        "  zero_orgs.append(org[\"organism\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPfxwr6AgbdH",
        "outputId": "660dfd74-46e4-409e-f034-c50e16df711b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "339"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(zero_orgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8zvT3rMg11r"
      },
      "outputs": [],
      "source": [
        "##### GETS TAXIDS FROM LIST OF TAXONOMY RANKS ######\n",
        "\n",
        "import time\n",
        "\n",
        "IDs = []\n",
        "ID = {\"organism\": \"\", \"txid\": \"\", \"count\": \"\"}\n",
        "\n",
        "# Iterates through organisms\n",
        "for organism_name in zero_orgs:\n",
        "  # Construct the URL for the NCBI Taxonomy API\n",
        "  base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
        "  search_url = base_url + \"esearch.fcgi?db=taxonomy&term=\" + organism_name\n",
        "\n",
        "  # Send a GET request to the API\n",
        "  response = requests.get(search_url)\n",
        "  data = response.text\n",
        "\n",
        "  # Extract the TaxID from the response\n",
        "  if data.find(\"<Id>\")!=-1:\n",
        "    taxid = data[data.find(\"<Id>\")+4:data.find(\"</Id>\")]\n",
        "    print(f\"TaxID for {organism_name}: {taxid}\")\n",
        "  else:\n",
        "    taxid = \"\"\n",
        "    print(f\"TaxID not found for {organism_name}\")\n",
        "\n",
        "  ID[\"organism\"]=organism_name\n",
        "  ID[\"txid\"]=taxid + \"[ORGN]\"\n",
        "\n",
        "  # Construct the URL for the NCBI Taxonomy API\n",
        "  base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
        "  search_url = base_url + \"esearch.fcgi?db=taxonomy&term=\" + organism_name + \"[Organism]\"\n",
        "\n",
        "  # Send a GET request to the API\n",
        "  response = requests.get(search_url)\n",
        "  data = response.text\n",
        "\n",
        "  # Extract the TaxID from the response\n",
        "  if data.find(\"<Count>\")!=-1:\n",
        "    count = data[data.find(\"<Count>\")+7:data.find(\"</Count>\")]\n",
        "    print(f\"Count for {organism_name}: {count}\")\n",
        "  else:\n",
        "    count = 0\n",
        "    print(f\"Count not found for {organism_name}\")\n",
        "\n",
        "  ID[\"count\"]=count\n",
        "  IDs.append(ID.copy())\n",
        "  #time.sleep(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_AUlyvKia0N"
      },
      "outputs": [],
      "source": [
        "IDs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MA3__KWk9Vcf"
      },
      "outputs": [],
      "source": [
        "IDs[590:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdyKm_0Gsu8g"
      },
      "outputs": [],
      "source": [
        "yeast_seq = \"MSVTGTEIDSDTAKNILSVDELQNYGINASDLQKLKSGGIYTVNTVLSTTRRHLCKIKGLSEVKVEKIKEAAGKIIQVGFIPATVQLDIRQRVYSLSTGSKQLDSILGGGIMTMSITEVFGEFRCGKTQMSHTLCVTTQLPREMGGGEGKVAYIDTEGTFRPERIKQIAEGYELDPESCLANVSYARALNSEHQMELVEQLGEELSSGDYRLIVVDSIMANFRVDYCGRGELSERQQKLNQHLFKLNRLAEEFNVAVFLTNQVQSDPGASALFASADGRKPIGGHVLAHASATRILLRKGRGDERVAKLQDSPDMPEKECVYVIGEKGITDSSD\"\n",
        "\n",
        "human_seq = \"MKEDQVVAEEPGFQDEEESLFQDIDLLQKHGINVADIKKLKSVGICTIKGIQMTTRRALCNVKGLSEAKVDKIKEAANKLIEPGFLTAFEYSEKRKMVFHITTGSQEFDKLLGGGIESMAITEAFGEFRTGKTQLSHTLCVTAQLPGAGGYPGGKIIFIDTENTFRPDRLRDIADRFNVDHDAVLDNVLYARAYTSEHQMELLDYVAAKFHEEAGIFKLLIIDSIMALFRVDFSGRGELAERQQKLAQMLSRLQKISEEYNVAVFVTNQMTADPGATMTFQADPKKPIGGHILAHASTTRISLRKGRGELRIAKIYDSPEMPENEATFAITAGGIGDAKE\"\n",
        "\n",
        "\n",
        "# List to store organisms without DMC1 or HSLIM15 entry\n",
        "containsDmc1 = []\n",
        "lacksDmc1 = []\n",
        "fewerThan100 = []\n",
        "\n",
        "for ID in IDs[599:600]:\n",
        "  hasDmc1 = False\n",
        "\n",
        "  if int(ID[\"count\"]) > 100:\n",
        "    # Replace this with your actual query sequence in FASTA format\n",
        "    # query_seq = \">Query\\n\" + yeast_seq\n",
        "    query_seq = \">Query\\n\" + human_seq\n",
        "    order = ID[\"organism\"] + \"[ORGN]\"\n",
        "\n",
        "    # Perform pBLAST search\n",
        "    result = NCBIWWW.qblast(\"blastp\", \"nr\", query_seq, entrez_query=order, hitlist_size=10)\n",
        "\n",
        "    # Parse the BLAST results\n",
        "    rad51_parsed = NCBIXML.parse(result)\n",
        "\n",
        "    # Iterate through BLAST records\n",
        "    for record in rad51_parsed:\n",
        "      for alignment in record.alignments:\n",
        "        if (alignment.title.find(\"dmc1\") != -1 or alignment.title.find(\"Dmc1\") != -1\n",
        "            or alignment.title.find(\"DMC1\") != -1or alignment.title.find(\"lim15\") != -1\n",
        "            or alignment.title.find(\"Lim15\") != -1 or alignment.title.find(\"LIM15\") != -1\n",
        "            or alignment.hsps[0].expect < 1e-120): # THIS IS THE FILTER CRITERIA\n",
        "          hasDmc1 = True\n",
        "      if hasDmc1:\n",
        "        containsDmc1.append(ID[\"organism\"])\n",
        "        print(ID[\"organism\"] + \" has Dmc1\")\n",
        "      else:\n",
        "        lacksDmc1.append(ID[\"organism\"])\n",
        "        print(ID[\"organism\"] + \" lack Dmc1!\")\n",
        "  else:\n",
        "    fewerThan100.append(ID[\"organism\"])\n",
        "    print(ID[\"organism\"] + \" has fewer than 100 entries\")\n",
        "\n",
        "with open(path + \"output.txt\", \"w\") as output:\n",
        "  output.write('-----containsDmc1-----\\n')\n",
        "  for order in containsDmc1:\n",
        "    output.write(order + \"\\n\")\n",
        "  output.write('\\n-----lacksDmc1-----\\n')\n",
        "  for order in lacksDmc1:\n",
        "    output.write(order + \"\\n\")\n",
        "  output.write('\\n-----fewerThan100-----\\n')\n",
        "  for order in fewerThan100:\n",
        "    output.write(str(order) + \"\\n\")\n",
        "\n",
        "files.download(\"output.txt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVveXr0FChhs"
      },
      "source": [
        "## October Plan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A64AkjanCuo-"
      },
      "outputs": [],
      "source": [
        "### Reads existing csv for dictionary ###\n",
        "\n",
        "path = %env STORAGE_FILE_PATH\n",
        "\n",
        "orders = []\n",
        "with open(path +'plant_orders.csv', 'r') as csvfile:\n",
        "  csv_reader = csv.DictReader(csvfile)\n",
        "  for row in csv_reader:\n",
        "    orders.append(row[\"Order\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tz1EedfLEaFJ"
      },
      "outputs": [],
      "source": [
        "orders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6w--Ky1CkX8"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "IDs = []\n",
        "ID = {\"organism\": \"\", \"txid\": \"\"}\n",
        "\n",
        "# Iterates through organisms\n",
        "for organism_name in orders:\n",
        "  time.sleep(0.25)\n",
        "\n",
        "  # Construct the URL for the NCBI Taxonomy API\n",
        "  base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
        "  search_url = base_url + \"esearch.fcgi?db=taxonomy&term=\" + organism_name\n",
        "\n",
        "  # Send a GET request to the API\n",
        "  response = requests.get(search_url)\n",
        "  data = response.text\n",
        "\n",
        "  # Extract the TaxID from the response\n",
        "  if data.find(\"<Id>\")!=-1:\n",
        "    taxid = data[data.find(\"<Id>\")+4:data.find(\"</Id>\")]\n",
        "    print(f\"TaxID for {organism_name}: {taxid}\")\n",
        "  else:\n",
        "    # Construct the URL for the NCBI Taxonomy API\n",
        "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
        "    search_url = base_url + \"esearch.fcgi?db=taxonomy&term=\" + organism_name\n",
        "\n",
        "    # Send a GET request to the API\n",
        "    response = requests.get(search_url)\n",
        "    data = response.text\n",
        "\n",
        "    # Extract the TaxID from the response\n",
        "    if data.find(\"<Id>\")!=-1:\n",
        "      taxid = data[data.find(\"<Id>\")+4:data.find(\"</Id>\")]\n",
        "      print(f\"TaxID for {organism_name}: {taxid}\")\n",
        "    else:\n",
        "      taxid = \"\"\n",
        "      print(f\"TaxID not found for {organism_name}\")\n",
        "\n",
        "  ID[\"organism\"]=organism_name\n",
        "  ID[\"txid\"]=taxid + \"[ORGN]\"\n",
        "\n",
        "  IDs.append(ID.copy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HipTLnTrPUTd"
      },
      "outputs": [],
      "source": [
        "IDs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0bMGx5TPOJc"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "field_names = ['organism', 'txid']\n",
        "\n",
        "with open(path +'plant_orders_txid.csv', 'w') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames = field_names)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(IDs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28LXWH78PaQ6"
      },
      "outputs": [],
      "source": [
        "files.download(path +'plant_orders_txid.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrz0awbfLiZ8"
      },
      "source": [
        "### Txid CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBUcU9Wfp0ov"
      },
      "outputs": [],
      "source": [
        "### Reads existing csv for dictionary ###\n",
        "\n",
        "path = %env STORAGE_FILE_PATH\n",
        "\n",
        "IDs = []\n",
        "order = {\"organism\":\"\",\"txid\":\"\"}\n",
        "with open(path +'plant_orders_txid.csv', 'r') as csvfile:\n",
        "  csv_reader = csv.DictReader(csvfile)\n",
        "  for row in csv_reader:\n",
        "    order[\"organism\"] = row[\"organism\"]\n",
        "    order[\"txid\"] = row[\"txid\"]\n",
        "    IDs.append(order.copy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okvHyNqfPQQE",
        "outputId": "ccb27bcc-022e-44ba-9caa-bd2149ff8a95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "76"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(IDs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "SI1uMydMHHgC",
        "outputId": "b2d9dccc-a36e-4d1c-a60c-65cc536084f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Grimmiales lack Dmc1\n",
            "Hookeriales lack Dmc1\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_9afb99b2-426d-4678-98bf-98b91ef336f4\", \"output.txt\", 91)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# List to store organisms without DMC1 or HSLIM15 entry\n",
        "containsDmc1 = []\n",
        "lacksDmc1 = []\n",
        "fewerThan100 = []\n",
        "\n",
        "yeast_seq = \"MSVTGTEIDSDTAKNILSVDELQNYGINASDLQKLKSGGIYTVNTVLSTTRRHLCKIKGLSEVKVEKIKEAAGKIIQVGFIPATVQLDIRQRVYSLSTGSKQLDSILGGGIMTMSITEVFGEFRCGKTQMSHTLCVTTQLPREMGGGEGKVAYIDTEGTFRPERIKQIAEGYELDPESCLANVSYARALNSEHQMELVEQLGEELSSGDYRLIVVDSIMANFRVDYCGRGELSERQQKLNQHLFKLNRLAEEFNVAVFLTNQVQSDPGASALFASADGRKPIGGHVLAHASATRILLRKGRGDERVAKLQDSPDMPEKECVYVIGEKGITDSSD\"\n",
        "\n",
        "human_seq = \"MKEDQVVAEEPGFQDEEESLFQDIDLLQKHGINVADIKKLKSVGICTIKGIQMTTRRALCNVKGLSEAKVDKIKEAANKLIEPGFLTAFEYSEKRKMVFHITTGSQEFDKLLGGGIESMAITEAFGEFRTGKTQLSHTLCVTAQLPGAGGYPGGKIIFIDTENTFRPDRLRDIADRFNVDHDAVLDNVLYARAYTSEHQMELLDYVAAKFHEEAGIFKLLIIDSIMALFRVDFSGRGELAERQQKLAQMLSRLQKISEEYNVAVFVTNQMTADPGATMTFQADPKKPIGGHILAHASTTRISLRKGRGELRIAKIYDSPEMPENEATFAITAGGIGDAKE\"\n",
        "\n",
        "\n",
        "for ID in IDs[74:]:\n",
        "  hasDmc1 = False\n",
        "\n",
        "  # Replace this with your actual query sequence in FASTA format\n",
        "  query_seq = \">Query\\n\" + yeast_seq\n",
        "  #query_seq = \">Query\\n\" + human_seq\n",
        "  order = ID[\"organism\"] + \"[ORGN]\"\n",
        "\n",
        "  # Perform pBLAST search\n",
        "  result = NCBIWWW.qblast(\"blastp\", \"nr\", query_seq, entrez_query=order, hitlist_size=10)\n",
        "\n",
        "  # Parse the BLAST results\n",
        "  rad51_parsed = NCBIXML.parse(result)\n",
        "\n",
        "  # Iterate through BLAST records\n",
        "  for record in rad51_parsed:\n",
        "    for alignment in record.alignments:\n",
        "      if (alignment.title.find(\"dmc1\") != -1 or alignment.title.find(\"Dmc1\") != -1\n",
        "          or alignment.title.find(\"DMC1\") != -1 or alignment.title.find(\"lim15\") != -1\n",
        "          or alignment.title.find(\"Lim15\") != -1 or alignment.title.find(\"LIM15\") != -1\n",
        "          or alignment.hsps[0].expect < 1e-120): # THIS IS THE FILTER CRITERIA\n",
        "        hasDmc1 = True\n",
        "    if hasDmc1:\n",
        "      containsDmc1.append(ID[\"organism\"])\n",
        "      print(ID[\"organism\"] + \" has Dmc1\")\n",
        "    else:\n",
        "      lacksDmc1.append(ID[\"organism\"])\n",
        "      print(ID[\"organism\"] + \" lack Dmc1\")\n",
        "\n",
        "with open(path + \"output.txt\", \"w\") as output:\n",
        "  output.write('-----containsDmc1-----\\n')\n",
        "  for order in containsDmc1:\n",
        "    output.write(order + \"\\n\")\n",
        "  output.write('\\n-----lacksDmc1-----\\n')\n",
        "  for order in lacksDmc1:\n",
        "    output.write(order + \"\\n\")\n",
        "  output.write('\\n-----fewerThan100-----\\n')\n",
        "  for order in fewerThan100:\n",
        "    output.write(str(order) + \"\\n\")\n",
        "\n",
        "files.download(path + \"output.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqUc7IpCNPv7",
        "outputId": "be3907c5-44d9-4394-e99b-25f585527c76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Orthotrichales lack Rad51!\n",
            "Porellales lack Rad51!\n",
            "Grimmiales lack Rad51!\n",
            "Hookeriales lack Rad51!\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_cadcea34-4894-45a7-8689-64de07dc794a\", \"output.txt\", 95)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "### RAD51 CHECKLIST\n",
        "# List to store organisms without Rad51 entry\n",
        "containsRad51 = []\n",
        "lacksRad51 = []\n",
        "fewerThan100 = []\n",
        "\n",
        "yeast_Rad51 = \"MSQVQEQHISESQLQYGNGSLMSTVPADLSQSVVDGNGNGSSEDIEATNGSGDGGGLQEQAEAQGEMEDEAYDEAALGSFVPIEKLQVNGITMADVKKLRESGLHTAEAVAYAPRKDLLEIKGISEAKADKLLNEAARLVPMGFVTAADFHMRRSELICLTTGSKNLDTLLGGGVETGSITELFGEFRTGKSQLCHTLAVTCQIPLDIGGGEGKCLYIDTEGTFRPVRLVSIAQRFGLDPDDALNNVAYARAYNADHQLRLLDAAAQMMSESRFSLIVVDSVMALYRTDFSGRGELSARQMHLAKFMRALQRLADQFGVAVVVTNQVVAQVDGGMAFNPDPKKPIGGNIMAHSSTTRLGFKKGKGCQRLCKVVDSPCLPEAECVFAIYEDGVGDPREEDE\"\n",
        "human_Rad51 = \"MAMQMQLEANADTSVEEESFGPQPISRLEQCGINANDVKKLEEAGFHTVEAVAYAPKKELINIKGISEAKADKILAEAAKLVPMGFTTATEFHQRRSEIIQITTGSKELDKLLQGGIETGSITEMFGEFRTGKTQICHTLAVTCQLPIDRGGGEGKAMYIDTEGTFRPERLLAVAERYGLSGSDVLDNVAYARAFNTDHQTQLLYQASAMMVESRYALLIVDSATALYRTDYSGRGELSARQMHLARFLRMLLRLADEFGVAVVITNQVVAQVDGAAMFAADPKKPIGGNIIAHASTTRLYLRKGRGETRICKIYDSPCLPEAEAMFAINADGVGDAKD\"\n",
        "\n",
        "\n",
        "for ID in IDs[72:]:\n",
        "  hasRad51 = False\n",
        "\n",
        "  # Replace this with your actual query sequence in FASTA format\n",
        "  # query_seq = \">Query\\n\" + yeast_Rad51\n",
        "  query_seq = \">Query\\n\" + human_Rad51\n",
        "  order = ID[\"organism\"] + \"[ORGN]\"\n",
        "\n",
        "  # Perform pBLAST search\n",
        "  result = NCBIWWW.qblast(\"blastp\", \"nr\", query_seq, entrez_query=order, hitlist_size=10)\n",
        "\n",
        "  # Parse the BLAST results\n",
        "  rad51_parsed = NCBIXML.parse(result)\n",
        "\n",
        "  # Iterate through BLAST records\n",
        "  for record in rad51_parsed:\n",
        "    for alignment in record.alignments:\n",
        "      if (alignment.title.find(\"Rad51\") != -1 or alignment.title.find(\"RAD51\") != -1\n",
        "          or alignment.hsps[0].expect < 1e-120): # THIS IS THE FILTER CRITERIA\n",
        "        hasRad51 = True\n",
        "    if hasRad51:\n",
        "      containsRad51.append(ID[\"organism\"])\n",
        "      print(ID[\"organism\"] + \" has Rad51\")\n",
        "    else:\n",
        "      lacksRad51.append(ID[\"organism\"])\n",
        "      print(ID[\"organism\"] + \" lack Rad51!\")\n",
        "\n",
        "with open(path + \"output.txt\", \"w\") as output:\n",
        "  output.write('-----containsRad51-----\\n')\n",
        "  for order in containsRad51:\n",
        "    output.write(order + \"\\n\")\n",
        "  output.write('\\n-----lacksRad51-----\\n')\n",
        "  for order in lacksRad51:\n",
        "    output.write(order + \"\\n\")\n",
        "#  output.write('\\n-----fewerThan100-----\\n')\n",
        "#  for order in fewerThan100:\n",
        "#    output.write(str(order) + \"\\n\")\n",
        "\n",
        "files.download(path + \"output.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-uTdTZa9SlU"
      },
      "source": [
        "# November Plan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-XT_zw79WEr"
      },
      "source": [
        "The plan is to download the top 3 sequences and headers of each species, do a manual sifting of results so that it becomes one sequence per order. Then do an alignment and FastTree pipeline to create the newick tree. Then put it into a pdf form and do the highlighting for visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_Hh28IQucxg"
      },
      "outputs": [],
      "source": [
        "### Reads existing csv for dictionary ###\n",
        "\n",
        "orders = []\n",
        "with open(path +'metazoa_orders_pruned.csv', 'r') as csvfile:\n",
        "  csv_reader = csv.DictReader(csvfile)\n",
        "  for row in csv_reader:\n",
        "    orders.append(row[\"Order\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Arkr-EQHz9xz"
      },
      "outputs": [],
      "source": [
        "### Reads master csv in case progress is dropped ###\n",
        "\n",
        "master = pd.read_csv(path + \"metazoa_data_nov.csv\")\n",
        "master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghSBLZBjbUzS"
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "          \"Order\": [\"temp\"],\n",
        "          \"Title\": [\"temp\"],\n",
        "          \"Alignment Length\": [0],\n",
        "          \"Alignment Sequence\": [\"temp\"]\n",
        "      }\n",
        "master = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKEZjJ2D_Otc"
      },
      "outputs": [],
      "source": [
        "master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YEFGK7TYlyr",
        "outputId": "65d21d07-e393-4c83-8d29-20836ced1183"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Salmoniformes',\n",
              " 'Gadiformes',\n",
              " 'Atheriniformes',\n",
              " 'Cyprinodontiformes',\n",
              " 'Beloniformes']"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "orders[60:65]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAd2ViZKmukn",
        "outputId": "91c11ea1-8a5b-4c4a-d239-db0d88a235ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Podocopida done...\n",
            "Diphyllobothriidea done...\n",
            "Mesostigmata done...\n",
            "Phthiraptera done...\n",
            "Ephemeroptera done...\n",
            "Thysanoptera done...\n",
            "Procellariiformes done...\n",
            "Strigiformes done...\n",
            "Myliobatiformes done...\n",
            "Chaetodontiformes done...\n",
            "Syngnathiformes done...\n",
            "Anabantiformes done...\n",
            "Tetraodontiformes done...\n",
            "Entomobryomorpha done...\n",
            "Bivalvulida done...\n",
            "Symphypleona done...\n",
            "Parachela done...\n",
            "Philodinida done...\n",
            "Pseudoscorpiones done...\n",
            "Blenniiformes done...\n",
            "Pantopoda done...\n",
            "Bucerotiformes done...\n",
            "Siphonostomatoida done...\n",
            "Kurtiformes done...\n",
            "Ophidiiformes done...\n"
          ]
        }
      ],
      "source": [
        "def fetch_protein_sequence(accession_number):\n",
        "    try:\n",
        "        # Fetch the protein record using the accession number\n",
        "        handle = Entrez.efetch(db=\"protein\", id=accession_number, rettype=\"fasta\", retmode=\"text\")\n",
        "        record = handle.read()\n",
        "        handle.close()\n",
        "        return record\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "yeast_Rad51 = \"MSQVQEQHISESQLQYGNGSLMSTVPADLSQSVVDGNGNGSSEDIEATNGSGDGGGLQEQAEAQGEMEDEAYDEAALGSFVPIEKLQVNGITMADVKKLRESGLHTAEAVAYAPRKDLLEIKGISEAKADKLLNEAARLVPMGFVTAADFHMRRSELICLTTGSKNLDTLLGGGVETGSITELFGEFRTGKSQLCHTLAVTCQIPLDIGGGEGKCLYIDTEGTFRPVRLVSIAQRFGLDPDDALNNVAYARAYNADHQLRLLDAAAQMMSESRFSLIVVDSVMALYRTDFSGRGELSARQMHLAKFMRALQRLADQFGVAVVVTNQVVAQVDGGMAFNPDPKKPIGGNIMAHSSTTRLGFKKGKGCQRLCKVVDSPCLPEAECVFAIYEDGVGDPREEDE\"\n",
        "human_seq = \"MAMQMQLEANADTSVEEESFGPQPISRLEQCGINANDVKKLEEAGFHTVEAVAYAPKKELINIKGISEAKADKILAEAAKLVPMGFTTATEFHQRRSEIIQITTGSKELDKLLQGGIETGSITEMFGEFRTGKTQICHTLAVTCQLPIDRGGGEGKAMYIDTEGTFRPERLLAVAERYGLSGSDVLDNVAYARAFNTDHQTQLLYQASAMMVESRYALLIVDSATALYRTDYSGRGELSARQMHLARFLRMLLRLADEFGVAVVITNQVVAQVDGAAMFAADPKKPIGGNIIAHASTTRLYLRKGRGETRICKIYDSPCLPEAEAMFAINADGVGDAKD\"\n",
        "\n",
        "\n",
        "#query_seq = \">Query\\n\" + yeast_Rad51\n",
        "query_seq = \">Query\\n\" + human_seq\n",
        "\n",
        "for order in orders:\n",
        "  #### SET UP LIST OF ORDERS FROM SPREADSHEET ANALYSIS\n",
        "  order_query = order + \"[ORGN]\"\n",
        "\n",
        "  # Perform pBLAST search\n",
        "  result = NCBIWWW.qblast(\"blastp\", \"nr\", query_seq, entrez_query=order_query, hitlist_size=10)\n",
        "\n",
        "  # Parse the BLAST results\n",
        "  rad51_parsed = NCBIXML.parse(result)\n",
        "\n",
        "  # Extract information from XML parse\n",
        "  for record in rad51_parsed:\n",
        "    order_name = []\n",
        "    title = []\n",
        "    length = []\n",
        "    subject = []\n",
        "\n",
        "    for alignment in record.alignments:\n",
        "      t = alignment.title\n",
        "\n",
        "      order_name.append(order)\n",
        "      title.append(t)\n",
        "      length.append(alignment.hsps[0].align_length)\n",
        "\n",
        "      # Parses accession number and uses Entrez to fetch protein sequence\n",
        "      index = t.find(\"|\")\n",
        "      accession_number = t[index+1 : t[index+1:].find('|') + index+1]\n",
        "      protein_sequence = fetch_protein_sequence(accession_number)\n",
        "      subject.append(protein_sequence)\n",
        "\n",
        "    data = {\n",
        "          \"Order\": order_name,\n",
        "          \"Title\": title,\n",
        "          \"Alignment Length\": length,\n",
        "          \"Alignment Sequence\": subject\n",
        "      }\n",
        "    df = pd.DataFrame(data)\n",
        "    master = pd.concat([df,master], ignore_index=True)\n",
        "    master.to_csv(path + \"metazoa_data_nov.csv\", index=False)\n",
        "\n",
        "    print(order + \" done...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "r0jueMQestR2",
        "outputId": "a1644474-60c3-466e-a6a6-feaa18e5bf3d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Rhizophydiales'"
            ]
          },
          "execution_count": 171,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Kb2pHPPqggt"
      },
      "outputs": [],
      "source": [
        "master.to_csv(path + \"/nov_data/fungi_data_nov.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}